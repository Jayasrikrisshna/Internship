{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c594d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header Tags:\n",
      "\n",
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\">Main Page</h1>\n",
      "\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "#Q1 Program to display all header tags from wikipedia.org\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def wikip(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    heading=soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "    print('Header Tags:',*heading, sep='\\n\\n')\n",
    "wikip('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96c448a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>1931</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>1958</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Names  Year Rating\n",
       "0              The Shawshank Redemption  1994    9.2\n",
       "1                         The Godfather  1972    9.2\n",
       "2                       The Dark Knight  2008    9.0\n",
       "3                 The Godfather Part II  1974    9.0\n",
       "4                          12 Angry Men  1957    8.9\n",
       "..                                  ...   ...    ...\n",
       "95                               Jagten  2012    8.3\n",
       "96    M - Eine Stadt sucht einen Mörder  1931    8.3\n",
       "97                   North by Northwest  1959    8.3\n",
       "98                              Vertigo  1958    8.2\n",
       "99  Le fabuleux destin d'Amélie Poulain  2001    8.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2 IMDB Top 100 Moives\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def imdb(url):\n",
    "    Names = []\n",
    "    Year = []\n",
    "    Rating = []\n",
    "    url=('https://www.imdb.com/chart/top/?ref_=nv_mv_250')\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.content,'html.parser')\n",
    "    name=soup.find_all('td',class_=\"titleColumn\")\n",
    "    for i in name:\n",
    "        movie_name=i.find('a').get_text()\n",
    "        Names.append(movie_name)\n",
    "    year=soup.find_all('span',class_=\"secondaryInfo\")\n",
    "    for i in year:\n",
    "        Year.append(i.text.replace('(','').replace(')',''))\n",
    "    rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "    for i in rating:\n",
    "        Rating.append(i.text.replace('\\n',''))\n",
    "    movies=pd.DataFrame({})\n",
    "        \n",
    "    movies['Names']=Names\n",
    "    movies['Year']=Year\n",
    "    movies['Rating']=Rating\n",
    "    movies=movies[:100]\n",
    "    return(movies)\n",
    "        \n",
    "    \n",
    "df=imdb('https://www.imdb.com/chart/top/')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d49256a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Masaan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maheshinte Prathikaaram</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Names Rating  Year\n",
       "0                      Jai Bhim    8.4  2021\n",
       "1                    Anbe Sivam    8.4  2003\n",
       "2                       Golmaal    8.4  1979\n",
       "3                       Nayakan    8.4  1987\n",
       "4             Pariyerum Perumal    8.4  2018\n",
       "..                          ...    ...   ...\n",
       "95                       Masaan    8.0  2015\n",
       "96                      Kahaani    8.0  2012\n",
       "97  Baahubali 2: The Conclusion    8.0  2017\n",
       "98               Dil Chahta Hai    8.0  2001\n",
       "99      Maheshinte Prathikaaram    8.0  2016\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3 IMDB Top rated Indian Movies\n",
    "\n",
    "#from bs4 import BeautifulSoup\n",
    "#import requests\n",
    "#import re\n",
    "#import pandas as pd\n",
    "#url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "#response = requests.get(url)\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#movies = soup.find('tbody', class_=\"lister-list\").find_all('tr')\n",
    "#for movie in movies[:100]:\n",
    "    #name = movie.find('td',class_=\"titleColumn\").a.text\n",
    "    #rank = movie.find('td',class_=\"titleColumn\").get_text(strip=True).split('.')[0]\n",
    "    #year = movie.find('td',class_=\"titleColumn\").span.text.strip('()')\n",
    "    #rating = movie.find('td',class_=\"ratingColumn imdbRating\").strong.text\n",
    "    #print(rank, name, year, rating)\n",
    "    \n",
    "    \n",
    "def imdb_indian(url):\n",
    "    Names=[]\n",
    "    Rating=[]\n",
    "    Year=[]\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.content,'html.parser')\n",
    "    name=soup.find_all('td',class_=\"titleColumn\")\n",
    "    for i in name:\n",
    "        movie_name=i.find('a').get_text()\n",
    "        Names.append(movie_name)\n",
    "    rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "    for i in rating:\n",
    "        Rating.append(i.text.replace('\\n',''))\n",
    "    year=soup.find_all('span',class_=\"secondaryInfo\")\n",
    "    for i in year:\n",
    "        Year.append(i.text.replace('(','').replace(')',''))\n",
    "    import pandas as pd\n",
    "    movies=pd.DataFrame({})\n",
    "    movies['Names']=Names\n",
    "    movies['Rating']=Rating\n",
    "    movies['Year']=Year\n",
    "    movies=movies[:100]\n",
    "    return(movies)\n",
    "\n",
    "df=imdb_indian('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efd4f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shri Pranab Mukherjee (1935-2020) -> Term of Office: 25 July, 2012 to 25 July, 2017 \n",
      "Smt Pratibha Devisingh Patil (birth - 1934) -> Term of Office: 25 July, 2007 to 25 July, 2012 \n",
      "DR. A.P.J. Abdul Kalam (1931-2015) -> Term of Office: 25 July, 2002 to 25 July, 2007 \n",
      "Shri K. R. Narayanan (1920 - 2005) -> Term of Office: 25 July, 1997 to 25 July, 2002 \n",
      "Dr Shankar Dayal Sharma (1918-1999) -> Term of Office: 25 July, 1992 to 25 July, 1997 \n",
      "Shri R Venkataraman (1910-2009) -> Term of Office: 25 July, 1987 to 25 July, 1992 \n",
      "Giani Zail Singh (1916-1994) -> Term of Office: 25 July, 1982 to 25 July, 1987 \n",
      "Shri Neelam Sanjiva Reddy (1913-1996) -> Term of Office: 25 July, 1977 to 25 July, 1982 \n",
      "Dr. Fakhruddin Ali Ahmed (1905-1977) -> Term of Office: 24 August, 1974 to 11 February, 1977\n",
      "Shri Varahagiri Venkata Giri (1894-1980) -> Term of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974\n",
      "Dr. Zakir Husain (1897-1969) -> Term of Office: 13 May, 1967 to 3 May, 1969\n",
      "Dr. Sarvepalli Radhakrishnan (1888-1975) -> Term of Office: 13 May, 1962 to 13 May, 1967\n",
      "Dr. Rajendra Prasad (1884-1963)  -> Term of Office: 26 January, 1950 to 13 May, 1962\n"
     ]
    }
   ],
   "source": [
    "#Q4 Former President listing\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(url=\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "former_presidents=soup.find('ul',class_=\"listing cf\").find_all('li')\n",
    "for name in former_presidents:\n",
    "    names = name.find('div',class_=\"presidentListing\").h3.text\n",
    "    term = name.find('div',class_=\"presidentListing\").p.text \n",
    "    print(names,'->', term)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a3b1c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teams</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>12</td>\n",
       "      <td>1,505</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>22</td>\n",
       "      <td>2,756</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>19</td>\n",
       "      <td>2,005</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>22</td>\n",
       "      <td>2,304</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1,872</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>2,275</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>32</td>\n",
       "      <td>2,306</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teams matches points ratings\n",
       "0   New Zealand      12  1,505     125\n",
       "1       England      22  2,756     125\n",
       "2      Pakistan      19  2,005     106\n",
       "3         India      22  2,304     105\n",
       "4     Australia      23  2,325     101\n",
       "5  South Africa      19  1,872      99\n",
       "6    Bangladesh      24  2,275      95\n",
       "7     Sri Lanka      29  2,658      92\n",
       "8   West Indies      32  2,306      72\n",
       "9   Afghanistan      18  1,238      69"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5 To scrape Cricket Rankings\n",
    "#a top 10 ODI teams\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "response = requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "def topteams(url):\n",
    "   \n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points=[]\n",
    "    ratings=[]\n",
    "    team=soup.find_all('span',class_='u-hide-phablet')\n",
    "    for i in team:\n",
    "        teams.append(i.text)\n",
    "    teams=teams[:10]\n",
    "    #for the top team\n",
    "    match_top=soup.find_all('td',class_='rankings-block__banner--matches')\n",
    "    for i in match_top:\n",
    "        matches.append(i.text)\n",
    "    #for the remaining other teams\n",
    "    match=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(0,len(match),2):\n",
    "        matches.append(match[i].text)\n",
    "    matches=matches[:10]\n",
    "    #for the top team points\n",
    "    point_top=soup.find_all('td',class_='rankings-block__banner--points')\n",
    "    for i in point_top:\n",
    "        points.append(i.text)\n",
    "    #for the remaining points\n",
    "    point=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(1,len(match),2):\n",
    "        points.append(point[i].text)\n",
    "    points=points[:10]\n",
    "    \n",
    "    rating=soup.find_all('td',class_='rankings-block__banner--rating u-text-right')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    rating=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    ratings=ratings[:10]\n",
    "    import pandas as pd\n",
    "    teams_odi=pd.DataFrame({})\n",
    "    teams_odi['teams']=teams\n",
    "    teams_odi['matches']=matches\n",
    "    teams_odi['points']=points\n",
    "    teams_odi['ratings']=ratings\n",
    "    return(teams_odi)\n",
    "\n",
    "df=topteams('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "903326fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 players teams ratings\n",
       "0             Babar Azam   PAK     892\n",
       "1            Imam-ul-Haq   PAK     815\n",
       "2            Virat Kohli   IND     811\n",
       "3           Rohit Sharma   IND     791\n",
       "4        Quinton de Kock    SA     789\n",
       "5            Ross Taylor    NZ     775\n",
       "6  Rassie van der Dussen    SA     769\n",
       "7         Jonny Bairstow   ENG     752\n",
       "8           David Warner   AUS     737\n",
       "9              Shai Hope    WI     718"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b Top 10 ODI Batsmen\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "response = requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "def topplayers(url):\n",
    "   \n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    player=soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in player:\n",
    "        players.append(i.text)\n",
    "    player=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in player:\n",
    "        players.append(i.find('a').text)\n",
    "        \n",
    "    players=players[:10]\n",
    "    \n",
    "    team_top=soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in team_top:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    team=soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    \n",
    "    rating=soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    rating=soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    import pandas as pd\n",
    "    players_odi=pd.DataFrame({})\n",
    "    players_odi['players']=players\n",
    "    players_odi['teams']=teams\n",
    "    players_odi['ratings']=ratings\n",
    "    return(players_odi)\n",
    "df=topplayers('https://www.icc-cricket.com/rankings/mens/team-rankings/odi/batting')\n",
    "df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0b5d173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            players teams ratings\n",
       "0       Trent Boult    NZ     726\n",
       "1        Matt Henry    NZ     683\n",
       "2    Shaheen Afridi   PAK     681\n",
       "3      Chris Woakes   ENG     680\n",
       "4    Jasprit Bumrah   IND     679\n",
       "5    Josh Hazlewood   AUS     679\n",
       "6  Mujeeb Ur Rahman   AFG     676\n",
       "7      Mehedi Hasan   BAN     661\n",
       "8     Mohammad Nabi   AFG     657\n",
       "9   Shakib Al Hasan   BAN     657"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c Top ODI Bowlers\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "response = requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "def topplayers(url):\n",
    "   \n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    player=soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in player:\n",
    "        players.append(i.text)\n",
    "    player=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in player:\n",
    "        players.append(i.find('a').text)\n",
    "        \n",
    "    players=players[:10]\n",
    "    \n",
    "    team_top=soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in team_top:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    team=soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    \n",
    "    rating=soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    rating=soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    import pandas as pd\n",
    "    players_odi=pd.DataFrame({})\n",
    "    players_odi['players']=players\n",
    "    players_odi['teams']=teams\n",
    "    players_odi['ratings']=ratings\n",
    "    return(players_odi)\n",
    "\n",
    "df=topplayers('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dd69b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teams</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>32</td>\n",
       "      <td>3,949</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,531</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>2,889</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>384</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teams matches points ratings\n",
       "0     Australia      29  4,837     167\n",
       "1  South Africa      32  3,949     123\n",
       "2       England      30  3,531     118\n",
       "3         India      29  2,889     100\n",
       "4   New Zealand      31  3,019      97\n",
       "5   West Indies      30  2,768      92\n",
       "6    Bangladesh      12    930      78\n",
       "7      Pakistan      30  1,962      65\n",
       "8     Sri Lanka       8    384      48\n",
       "9       Ireland       8    351      44"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6 To scrape Cricket rankings\n",
    "#a top 10 ODI teams Women\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "response = requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "def topwteams(url):\n",
    "   \n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points=[]\n",
    "    ratings=[]\n",
    "    team=soup.find_all('span',class_='u-hide-phablet')\n",
    "    for i in team:\n",
    "        teams.append(i.text)\n",
    "    teams=teams[:10]\n",
    "    #for the top team\n",
    "    match_top=soup.find_all('td',class_='rankings-block__banner--matches')\n",
    "    for i in match_top:\n",
    "        matches.append(i.text)\n",
    "    #for the remaining other teams\n",
    "    match=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(0,len(match),2):\n",
    "        matches.append(match[i].text)\n",
    "    matches=matches[:10]\n",
    "    #for the top team points\n",
    "    point_top=soup.find_all('td',class_='rankings-block__banner--points')\n",
    "    for i in point_top:\n",
    "        points.append(i.text)\n",
    "    #for the remaining points\n",
    "    point=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(1,len(match),2):\n",
    "        points.append(point[i].text)\n",
    "    points=points[:10]\n",
    "    \n",
    "    rating=soup.find_all('td',class_='rankings-block__banner--rating u-text-right')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    rating=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    ratings=ratings[:10]\n",
    "    import pandas as pd\n",
    "    teams_odi=pd.DataFrame({})\n",
    "    teams_odi['teams']=teams\n",
    "    teams_odi['matches']=matches\n",
    "    teams_odi['points']=points\n",
    "    teams_odi['ratings']=ratings\n",
    "    return(teams_odi)\n",
    "\n",
    "df=topwteams('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7caa4c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             players teams ratings\n",
       "0       Alyssa Healy   AUS     785\n",
       "1     Natalie Sciver   ENG     750\n",
       "2        Beth Mooney   AUS     748\n",
       "3    Laura Wolvaardt    SA     713\n",
       "4        Meg Lanning   AUS     710\n",
       "5     Rachael Haynes   AUS     701\n",
       "6  Amy Satterthwaite    NZ     681\n",
       "7    Smriti Mandhana   IND     669\n",
       "8     Tammy Beaumont   ENG     659\n",
       "9       Ellyse Perry   AUS     642"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b Top ODI Women Batting Players\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "response = requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "def topplayers(url):\n",
    "   \n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    player=soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in player:\n",
    "        players.append(i.text)\n",
    "    player=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in player:\n",
    "        players.append(i.find('a').text)\n",
    "        \n",
    "    players=players[:10]\n",
    "    \n",
    "    team_top=soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in team_top:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    team=soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    \n",
    "    rating=soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    rating=soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    import pandas as pd\n",
    "    players_odi=pd.DataFrame({})\n",
    "    players_odi['players']=players\n",
    "    players_odi['teams']=teams\n",
    "    players_odi['ratings']=ratings\n",
    "    return(players_odi)\n",
    "df=topplayers('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f92f1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sune Luus</td>\n",
       "      <td>SA</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            players teams ratings\n",
       "0    Natalie Sciver   ENG     393\n",
       "1      Ellyse Perry   AUS     374\n",
       "2   Hayley Matthews    WI     338\n",
       "3    Marizanne Kapp    SA     338\n",
       "4       Amelia Kerr    NZ     335\n",
       "5  Ashleigh Gardner   AUS     269\n",
       "6     Deepti Sharma   IND     249\n",
       "7     Jess Jonassen   AUS     245\n",
       "8         Sune Luus    SA     223\n",
       "9   Katherine Brunt   ENG     221"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c Top !0 ODI Women all rounders\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "response = requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "def topplayers(url):\n",
    "   \n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    player=soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in player:\n",
    "        players.append(i.text)\n",
    "    player=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in player:\n",
    "        players.append(i.find('a').text)\n",
    "        \n",
    "    players=players[:10]\n",
    "    \n",
    "    team_top=soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in team_top:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    team=soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    \n",
    "    rating=soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    rating=soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    import pandas as pd\n",
    "    players_odi=pd.DataFrame({})\n",
    "    players_odi['players']=players\n",
    "    players_odi['teams']=teams\n",
    "    players_odi['ratings']=ratings\n",
    "    return(players_odi)\n",
    "df=topplayers('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19ed45a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watch for these 4 red flags at job interviews,...</td>\n",
       "      <td>16 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/watch-for-thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goldman's stock picks for the multitrillion do...</td>\n",
       "      <td>24 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/goldmans-stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snap announces Snapchat+ subscription plan tha...</td>\n",
       "      <td>39 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/snapchat-plus-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim Cramer invested $100 a month in his 20s—ev...</td>\n",
       "      <td>50 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/jim-cramer-i-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crypto exchange CoinFlex claims 'Bitcoin Jesus...</td>\n",
       "      <td>52 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/crypto-exchang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Another crypto 'washout' is coming before inve...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/theres-another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3 ways the Supreme Court's decision on Roe cou...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/supreme-court-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Buy now, pay later refunds can get complicated...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/buy-now-pay-la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What Cramer is watching Wednesday — mass chip ...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/what-cramer-is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Watch Fed Chair Powell talk live about the eco...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/watch-fed-chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wednesday's top analyst calls: Tesla, Goldman ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/-wednesday-str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analysts still see earnings rising even as the...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/head-scratcher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Congested Port of Oakland slashing free wait t...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/port-of-oaklan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Delta offers free flight changes over July Fou...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/delta-offers-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>‘We are in a hybrid war,’ German foreign minis...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Crypto hedge fund Three Arrows Capital plunges...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/crypto-hedge-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stocks making the biggest moves premarket: Gen...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5 things to know before the stock market opens...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/5-things-to-kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bed Bath &amp; Beyond replaces CEO as retailer's s...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/bed-bath-beyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bitcoin briefly drops below $20,000 again as p...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/bitcoin-btc-br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Retirees planning to travel should check Medic...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/retirees-trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sell Upstart as rising rates weaken borrowing ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/sell-upstart-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mortgage demand stalls again, even as interest...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/mortgage-deman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Movies have momentum for a strong 2022, if inf...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/top-gun-maveri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spirit fight goes down to the wire with compet...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/spirit-airline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bank of America says Goldman Sachs will thrive...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/bank-of-americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sony looks beyond the PlayStation 5 with its o...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/sony-unveils-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Putin must be stopped in battlefield, not with...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/putin-needs-to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Buy Penn National as it benefits from pent-up ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/buy-penn-natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Atlantic Equities says buy McDonald's, a 'defe...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/atlantic-equit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time  \\\n",
       "0   Watch for these 4 red flags at job interviews,...   16 Min Ago   \n",
       "1   Goldman's stock picks for the multitrillion do...   24 Min Ago   \n",
       "2   Snap announces Snapchat+ subscription plan tha...   39 Min Ago   \n",
       "3   Jim Cramer invested $100 a month in his 20s—ev...   50 Min Ago   \n",
       "4   Crypto exchange CoinFlex claims 'Bitcoin Jesus...   52 Min Ago   \n",
       "5   Another crypto 'washout' is coming before inve...   1 Hour Ago   \n",
       "6   3 ways the Supreme Court's decision on Roe cou...   1 Hour Ago   \n",
       "7   Buy now, pay later refunds can get complicated...   1 Hour Ago   \n",
       "8   What Cramer is watching Wednesday — mass chip ...   1 Hour Ago   \n",
       "9   Watch Fed Chair Powell talk live about the eco...  2 Hours Ago   \n",
       "10  Wednesday's top analyst calls: Tesla, Goldman ...  2 Hours Ago   \n",
       "11  Analysts still see earnings rising even as the...  2 Hours Ago   \n",
       "12  Congested Port of Oakland slashing free wait t...  2 Hours Ago   \n",
       "13  Delta offers free flight changes over July Fou...  2 Hours Ago   \n",
       "14  ‘We are in a hybrid war,’ German foreign minis...  2 Hours Ago   \n",
       "15  Crypto hedge fund Three Arrows Capital plunges...  3 Hours Ago   \n",
       "16  Stocks making the biggest moves premarket: Gen...  3 Hours Ago   \n",
       "17  5 things to know before the stock market opens...  3 Hours Ago   \n",
       "18  Bed Bath & Beyond replaces CEO as retailer's s...  3 Hours Ago   \n",
       "19  Bitcoin briefly drops below $20,000 again as p...  3 Hours Ago   \n",
       "20  Retirees planning to travel should check Medic...  3 Hours Ago   \n",
       "21  Sell Upstart as rising rates weaken borrowing ...  3 Hours Ago   \n",
       "22  Mortgage demand stalls again, even as interest...  4 Hours Ago   \n",
       "23  Movies have momentum for a strong 2022, if inf...  4 Hours Ago   \n",
       "24  Spirit fight goes down to the wire with compet...  4 Hours Ago   \n",
       "25  Bank of America says Goldman Sachs will thrive...  4 Hours Ago   \n",
       "26  Sony looks beyond the PlayStation 5 with its o...  4 Hours Ago   \n",
       "27  Putin must be stopped in battlefield, not with...  4 Hours Ago   \n",
       "28  Buy Penn National as it benefits from pent-up ...  4 Hours Ago   \n",
       "29  Atlantic Equities says buy McDonald's, a 'defe...  5 Hours Ago   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2022/06/29/watch-for-thes...  \n",
       "1   https://www.cnbc.com/2022/06/29/goldmans-stock...  \n",
       "2   https://www.cnbc.com/2022/06/29/snapchat-plus-...  \n",
       "3   https://www.cnbc.com/2022/06/29/jim-cramer-i-i...  \n",
       "4   https://www.cnbc.com/2022/06/29/crypto-exchang...  \n",
       "5   https://www.cnbc.com/2022/06/29/theres-another...  \n",
       "6   https://www.cnbc.com/2022/06/29/supreme-court-...  \n",
       "7   https://www.cnbc.com/2022/06/29/buy-now-pay-la...  \n",
       "8   https://www.cnbc.com/2022/06/29/what-cramer-is...  \n",
       "9   https://www.cnbc.com/2022/06/29/watch-fed-chai...  \n",
       "10  https://www.cnbc.com/2022/06/29/-wednesday-str...  \n",
       "11  https://www.cnbc.com/2022/06/29/head-scratcher...  \n",
       "12  https://www.cnbc.com/2022/06/29/port-of-oaklan...  \n",
       "13  https://www.cnbc.com/2022/06/29/delta-offers-f...  \n",
       "14  https://www.cnbc.com/2022/06/29/russia-ukraine...  \n",
       "15  https://www.cnbc.com/2022/06/29/crypto-hedge-f...  \n",
       "16  https://www.cnbc.com/2022/06/29/stocks-making-...  \n",
       "17  https://www.cnbc.com/2022/06/29/5-things-to-kn...  \n",
       "18  https://www.cnbc.com/2022/06/29/bed-bath-beyon...  \n",
       "19  https://www.cnbc.com/2022/06/29/bitcoin-btc-br...  \n",
       "20  https://www.cnbc.com/2022/06/29/retirees-trave...  \n",
       "21  https://www.cnbc.com/2022/06/29/sell-upstart-a...  \n",
       "22  https://www.cnbc.com/2022/06/29/mortgage-deman...  \n",
       "23  https://www.cnbc.com/2022/06/29/top-gun-maveri...  \n",
       "24  https://www.cnbc.com/2022/06/29/spirit-airline...  \n",
       "25  https://www.cnbc.com/2022/06/29/bank-of-americ...  \n",
       "26  https://www.cnbc.com/2022/06/29/sony-unveils-i...  \n",
       "27  https://www.cnbc.com/2022/06/29/putin-needs-to...  \n",
       "28  https://www.cnbc.com/2022/06/29/buy-penn-natio...  \n",
       "29  https://www.cnbc.com/2022/06/29/atlantic-equit...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7 Python program to scrape the news details\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url=('https://www.cnbc.com/world/?region=world')\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "head=[]\n",
    "for i in soup.find_all(\"a\",class_=\"LatestNews-headline\"):\n",
    "    head.append(i.text)\n",
    "time=[]\n",
    "for i in soup.find_all(\"time\",class_=\"LatestNews-timestamp\"):\n",
    "    time.append(i.text)\n",
    "link=[]\n",
    "for i in soup.find_all(\"a\",class_=\"LatestNews-headline\"):\n",
    "    link.append(i['href'])\n",
    "df=pd.DataFrame({\"Headline\":head,\"Time\":time,\"Link\":link})\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d4b244a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                        Publication h5-index h5-median\n",
       "0     1                                             Nature      444       667\n",
       "1     2                The New England Journal of Medicine      432       780\n",
       "2     3                                            Science      401       614\n",
       "3     4  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5                                         The Lancet      354       635\n",
       "..  ...                                                ...      ...       ...\n",
       "95   96                       Journal of Business Research      145       233\n",
       "96   97                                   Molecular Cancer      145       209\n",
       "97   98                                            Sensors      145       201\n",
       "98   99                              Nature Climate Change      144       228\n",
       "99  100                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q10 python program to scrape the details of top publications from Google Scholar form\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url=('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "rank=[]\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text.replace(\".\",\"\").split()[0])\n",
    "publication=[]\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "index=[]\n",
    "for i in soup.find_all(\"a\",class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    index.append(i.text)\n",
    "median=[]\n",
    "for i in soup.find_all(\"span\",class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    median.append(i.text)\n",
    "    \n",
    "df=pd.DataFrame({\"Rank\":rank,\"Publication\":publication,\"h5-index\":index,\"h5-median\":median})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb565a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               Author  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8 a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url=('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "title=[]\n",
    "for i in soup.find_all(\"h2\",class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    title.append(i.text)\n",
    "author=[]\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    author.append(i.text)\n",
    "pubdate=[]\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    pubdate.append(i.text)\n",
    "link=[]\n",
    "for i in soup.find_all(\"a\",class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    link.append(i['href'])\n",
    "    \n",
    "df=pd.DataFrame({\"Title\":title,\"Author\":author,\"Published Date\":pubdate,\"Link\":link})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "302968e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>North Indian, Mughlai, Desserts, Beverages</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>European, Italian, Asian, Continental</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Restaurant Name  \\\n",
       "0                    Castle Barbeque   \n",
       "1                    Jungle Jamboree   \n",
       "2                    Castle Barbeque   \n",
       "3                         Cafe Knosh   \n",
       "4               The Barbeque Company   \n",
       "5                        India Grill   \n",
       "6                     Delhi Barbeque   \n",
       "7   The Monarch - Bar Be Que Village   \n",
       "8                         World Cafe   \n",
       "9                  Indian Grill Room   \n",
       "10                   Mad 4 Bar B Que   \n",
       "11                       Barbeque 29   \n",
       "12                        Glasshouse   \n",
       "\n",
       "                                        Cuisine  \\\n",
       "0                         North Indian, Chinese   \n",
       "1                  North Indian, Asian, Italian   \n",
       "2                         Chinese, North Indian   \n",
       "3                          Italian, Continental   \n",
       "4                         North Indian, Chinese   \n",
       "5                         North Indian, Italian   \n",
       "6                                  North Indian   \n",
       "7                                  North Indian   \n",
       "8                         North Indian, Italian   \n",
       "9                         North Indian, Mughlai   \n",
       "10                                 North Indian   \n",
       "11   North Indian, Mughlai, Desserts, Beverages   \n",
       "12        European, Italian, Asian, Continental   \n",
       "\n",
       "                                             Location  \\\n",
       "0                      Connaught Place, Central Delhi   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "4                  Gardens Galleria,Sector 38A, Noida   \n",
       "5                Hilton Garden Inn,Saket, South Delhi   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "10                               Sector 29, Faridabad   \n",
       "11                                     NIT, Faridabad   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...   \n",
       "\n",
       "                                                Image  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9 a python program to scrape mentioned details from dineout.co.in Restaurant name Cuisine Location  Ratings Image URL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url=('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "name=[]\n",
    "for i in soup.find_all(\"a\",class_=\"restnt-name ellipsis\"):\n",
    "    name.append(i.text)\n",
    "cuisine=[]\n",
    "for i in soup.find_all(\"span\",class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text.split(\"|\")[1])\n",
    "loc=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(i.text)\n",
    "rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "image=[]\n",
    "for i in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "    image.append(i['data-src'])\n",
    "\n",
    "    \n",
    "df=pd.DataFrame({\"Restaurant Name\":name,\"Cuisine\":cuisine,\"Location\":loc,\"Image\":image})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9b67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
